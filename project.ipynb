{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN FOOD NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import folium\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "#from google.cloud import translate\n",
    "#import pycountry\n",
    "#import emoji\n",
    "\n",
    "#translate_client = translate.Client()\n",
    "\n",
    "from py_translator import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a data folder where the .csv file will be stored and also a maps folder where .html maps will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "maps_folder = './maps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'en.openfoodfacts.org.products.csv'\n",
    "countryfile = 'wikipedia-iso-country-codes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_col = [\n",
    "    \"product_name\",\n",
    "    \"generic_name\",\n",
    "    \"quantity\",\n",
    "    \"brands\",\n",
    "    \"brands_tags\",\n",
    "    \"categories\",\n",
    "    \"categories_tags\",\n",
    "    \"categories_en\",\n",
    "    \"manufacturing_places\",\n",
    "    \"manufacturing_places_tags\",\n",
    "    \"labels\",\n",
    "    \"labels_tags\",\n",
    "    \"labels_en\",\n",
    "    \"purchase_places\",\n",
    "    \"countries\",\n",
    "    \"countries_tags\",\n",
    "    \"countries_en\",\n",
    "    \"ingredients_text\",\n",
    "    \"allergens\",\n",
    "    \"allergens_en\",\n",
    "    \"traces\",\n",
    "    \"traces_tags\",\n",
    "    \"traces_en\",\n",
    "    \"nutrition_grade_uk\",\n",
    "    \"nutrition_grade_fr\",\n",
    "    \"main_category\",\n",
    "    \"main_category_en\",\n",
    "    \"energy_100g\",\n",
    "    \"energy-from-fat_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"trans-fat_100g\",\n",
    "    \"cholesterol_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\",\n",
    "    \"alcohol_100g\",\n",
    "    \"calcium_100g\",\n",
    "    \"iron_100g\",\n",
    "    \"carbon-footprint_100g\",\n",
    "    \"nutrition-score-fr_100g\",\n",
    "    \"nutrition-score-uk_100g\",\n",
    "    \"glycemic-index_100g\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = pd.read_csv(data_folder + filename, \n",
    "                      sep='\\t',\n",
    "                      header=0,\n",
    "                      usecols = using_col,\n",
    "                      quotechar='\"', \n",
    "                      low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of the data set are: \n",
      " product_name                  object\n",
      "generic_name                  object\n",
      "quantity                      object\n",
      "brands                        object\n",
      "brands_tags                   object\n",
      "categories                    object\n",
      "categories_tags               object\n",
      "categories_en                 object\n",
      "manufacturing_places          object\n",
      "manufacturing_places_tags     object\n",
      "labels                        object\n",
      "labels_tags                   object\n",
      "labels_en                     object\n",
      "purchase_places               object\n",
      "countries                     object\n",
      "countries_tags                object\n",
      "countries_en                  object\n",
      "ingredients_text              object\n",
      "allergens                     object\n",
      "allergens_en                  object\n",
      "traces                        object\n",
      "traces_tags                   object\n",
      "traces_en                     object\n",
      "nutrition_grade_uk           float64\n",
      "nutrition_grade_fr            object\n",
      "main_category                 object\n",
      "main_category_en              object\n",
      "energy_100g                  float64\n",
      "energy-from-fat_100g         float64\n",
      "fat_100g                     float64\n",
      "saturated-fat_100g           float64\n",
      "trans-fat_100g               float64\n",
      "cholesterol_100g             float64\n",
      "carbohydrates_100g           float64\n",
      "sugars_100g                  float64\n",
      "fiber_100g                   float64\n",
      "proteins_100g                float64\n",
      "salt_100g                    float64\n",
      "sodium_100g                  float64\n",
      "alcohol_100g                 float64\n",
      "calcium_100g                 float64\n",
      "iron_100g                    float64\n",
      "carbon-footprint_100g        float64\n",
      "nutrition-score-fr_100g      float64\n",
      "nutrition-score-uk_100g      float64\n",
      "glycemic-index_100g          float64\n",
      "dtype: object\n",
      "The total size of the data set is: (693984, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>manufacturing_places</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vitória crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130 g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendiants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_name generic_name quantity brands brands_tags  \\\n",
       "0           Vitória crackers          NaN      NaN    NaN         NaN   \n",
       "1                      Cacao          NaN    130 g    NaN         NaN   \n",
       "2      Sauce Sweety chili 0%          NaN      NaN    NaN         NaN   \n",
       "3                  Mendiants          NaN      NaN    NaN         NaN   \n",
       "4  Salade de carottes râpées          NaN      NaN    NaN         NaN   \n",
       "\n",
       "  categories categories_tags categories_en manufacturing_places  \\\n",
       "0        NaN             NaN           NaN                  NaN   \n",
       "1        NaN             NaN           NaN                  NaN   \n",
       "2        NaN             NaN           NaN                  NaN   \n",
       "3        NaN             NaN           NaN                  NaN   \n",
       "4        NaN             NaN           NaN                  NaN   \n",
       "\n",
       "  manufacturing_places_tags         ...         proteins_100g salt_100g  \\\n",
       "0                       NaN         ...                   7.8      1.40   \n",
       "1                       NaN         ...                   NaN       NaN   \n",
       "2                       NaN         ...                   0.2      2.04   \n",
       "3                       NaN         ...                   NaN       NaN   \n",
       "4                       NaN         ...                   0.9      0.42   \n",
       "\n",
       "  sodium_100g alcohol_100g calcium_100g iron_100g carbon-footprint_100g  \\\n",
       "0    0.551181          NaN          NaN       NaN                   NaN   \n",
       "1         NaN          NaN          NaN       NaN                   NaN   \n",
       "2    0.803150          NaN          NaN       NaN                   NaN   \n",
       "3         NaN          NaN          NaN       NaN                   NaN   \n",
       "4    0.165354          NaN          NaN       NaN                   NaN   \n",
       "\n",
       "  nutrition-score-fr_100g nutrition-score-uk_100g glycemic-index_100g  \n",
       "0                     NaN                     NaN                 NaN  \n",
       "1                     NaN                     NaN                 NaN  \n",
       "2                     NaN                     NaN                 NaN  \n",
       "3                     NaN                     NaN                 NaN  \n",
       "4                     NaN                     NaN                 NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The types of the data set are: \\n\", format(food_df.dtypes))\n",
    "print (\"The total size of the data set is:\", format(food_df.shape) )\n",
    "food_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing product_name\n",
    "This section deals with NaN values for `product_name`. If it does not have a `product_name`, the `generic_name` was used. If neither field was filled, then a combination of `brands` and `categories_en`/`main_category` was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name: 25881\n"
     ]
    }
   ],
   "source": [
    "# remove rows where the columns we are interested in are all null\n",
    "food_df = food_df.dropna(subset=using_col, how='all')\n",
    "\n",
    "print(\"Number of rows w/missing product_name: {}\".format(len(food_df) - food_df['product_name'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    if pd.isnull(row['product_name']):\n",
    "        if pd.isnull(row['generic_name']):\n",
    "            if pd.isnull(row['main_category_en']) & pd.isnull(row['categories_en']) & pd.isnull(row['brands']):\n",
    "                return\n",
    "            else:\n",
    "                category_name = row['main_category_en']\n",
    "                if pd.isnull(category_name):\n",
    "                    category_name = row['categories_en']\n",
    "                return \"{} {}\".format(row['brands'], category_name)\n",
    "        else:\n",
    "            return row['generic_name']\n",
    "    else:\n",
    "        return row['product_name']\n",
    "    \n",
    "df = food_df.copy()\n",
    "\n",
    "df['product_name'] = df.apply(\n",
    "    lambda x: get_name(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name after modifications: 22458\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing product_name after modifications: {}\".format(len(df) - df['product_name'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns that we no longer need\n",
    "used_col = [\n",
    "    'generic_name',\n",
    "    'main_category',\n",
    "    'main_category_en',\n",
    "    'brands',\n",
    "    'brands_tags',\n",
    "    'categories',\n",
    "    'categories_tags',\n",
    "    'categories_en',\n",
    "]\n",
    "\n",
    "df = df.drop(used_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Values for Country\n",
    "This section deals with the missing values for `countries_en`. The `countries_en` column represents the countries where the product is sold. This column is important for our analysis because we want to analyze how viable it is to live in each country based off one's dietary restrictions.\n",
    "\n",
    "In order to fix these missing values, we decided to first fill the column with values from `purchase_places`, then `manufacturing_places`. We decided to use `purchase_places` because if it was purchased in a certain country, obviously it means the product is sold there as well. As for `manufacturing_places`, we assumed that it is most likely that a product manufactured in a country would be sold there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 459\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df) - df['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "('Expecting value: line 1 column 1 (char 0)', 'occurred at index 18733')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b3334ffd7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m df_1['countries_en'] = df_1.apply(\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtranslate_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4b3334ffd7d1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m df_1['countries_en'] = df_1.apply(\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtranslate_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-13-4b3334ffd7d1>\u001b[0m in \u001b[0;36mtranslate_country\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# got value from purchase_places or manufacturing_places\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0malt_country\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malt_country\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0men_alt_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt_country\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0men_alt_country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/py_translator/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/py_translator/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/py_translator/utils.py\u001b[0m in \u001b[0;36mformat_json\u001b[0;34m(original)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegacy_format_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/py_translator/utils.py\u001b[0m in \u001b[0;36mlegacy_format_json\u001b[0;34m(original)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: ('Expecting value: line 1 column 1 (char 0)', 'occurred at index 18733')"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "def translate_country(row):\n",
    "    if pd.isnull(row['countries_en']):\n",
    "        alt_country = None\n",
    "        if pd.notna(row['purchase_places']):\n",
    "            alt_country = row['purchase_places']\n",
    "        elif pd.notna(row['manufacturing_places']):\n",
    "            alt_country = row['manufacturing_places']\n",
    "            \n",
    "        # got value from purchase_places or manufacturing_places\n",
    "        if (not alt_country is None) and pd.notna(alt_country):\n",
    "            en_alt_country = translator.translate(text=alt_country, dest='en').text\n",
    "            return en_alt_country\n",
    "        else:\n",
    "            return   \n",
    "    else:\n",
    "        return row['countries_en']\n",
    "    \n",
    "df_1 = df.copy()\n",
    "\n",
    "df_1['countries_en'] = df_1.apply(\n",
    "    lambda x: translate_country(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 459\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df_1) - df_1['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/multiple countries: 28587\n",
      "Number of total rows: 693387\n"
     ]
    }
   ],
   "source": [
    "# drop rows without country\n",
    "df_1 = df_1.dropna(subset=['countries_en'])\n",
    "\n",
    "\n",
    "print(\"Number of rows w/multiple countries: {}\".format(\n",
    "    len(df_1[df_1['countries_en'].str.contains(',')])))\n",
    "\n",
    "print(\"Number of total rows: {}\".format(len(df_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are no longer needed\n",
    "used_col = [\n",
    "    'purchase_places',\n",
    "    'manufacturing_places',\n",
    "    'manufacturing_places_tags',\n",
    "    'countries_tags',\n",
    "    'countries',\n",
    "]\n",
    "\n",
    "df_1 = df_1.drop(used_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries_en</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Lion Peanut x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Moelleux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Pack de 2 Twix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Root Beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>France,Germany</td>\n",
       "      <td>Fuzetea schwarzer Tee Zitrone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             countries_en                   product_name\n",
       "173  France,United States                 Lion Peanut x2\n",
       "196  France,United States                       Moelleux\n",
       "205  France,United States                 Pack de 2 Twix\n",
       "290  France,United States                      Root Beer\n",
       "426        France,Germany  Fuzetea schwarzer Tee Zitrone"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that some countries_en are lists\n",
    "df_1[df_1['countries_en'].notnull() & df_1['countries_en'].str.contains(',')][['countries_en', 'product_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the list substring into an array\n",
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2['countries_en'] = df_2.apply(\n",
    "    lambda x: [x.strip() for x in x['countries_en'].split(',')],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# [x.strip() for x in my_string.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>countries_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>[France, United States]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_name             countries_en\n",
       "173  Lion Peanut x2  [France, United States]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that the countries has been properly split\n",
    "df_2[df_2.index == 173][['product_name', 'countries_en']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this subsection deals with standardizing the countries for each product. First, we notice that some products have more than one country in their `countries_en` field. In this case, we seperate/explode each country in the `countries_en` field so that each country has its own row for that item. Next, we join the countries with their respective country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Antarctica</td>\n",
       "      <td>AQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>AW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Australia</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bahamas</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>BY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Belize</td>\n",
       "      <td>BZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Benin</td>\n",
       "      <td>BJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>BM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bolivia, Plurinational State of</td>\n",
       "      <td>BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Tanzania, United Republic of</td>\n",
       "      <td>TZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Togo</td>\n",
       "      <td>TG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Tokelau</td>\n",
       "      <td>TK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>TM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Turks and Caicos Islands</td>\n",
       "      <td>TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>United States Minor Outlying Islands</td>\n",
       "      <td>UM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>UY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>UZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>VU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Venezuela, Bolivarian Republic of</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>VN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Virgin Islands, British</td>\n",
       "      <td>VG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Virgin Islands, U.S.</td>\n",
       "      <td>VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>EH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             country_name country_code\n",
       "0                             Afghanistan           AF\n",
       "1                           Åland Islands           AX\n",
       "2                                 Albania           AL\n",
       "3                                 Algeria           DZ\n",
       "4                          American Samoa           AS\n",
       "5                                 Andorra           AD\n",
       "6                                  Angola           AO\n",
       "7                                Anguilla           AI\n",
       "8                              Antarctica           AQ\n",
       "9                     Antigua and Barbuda           AG\n",
       "10                              Argentina           AR\n",
       "11                                Armenia           AM\n",
       "12                                  Aruba           AW\n",
       "13                              Australia           AU\n",
       "14                                Austria           AT\n",
       "15                             Azerbaijan           AZ\n",
       "16                                Bahamas           BS\n",
       "17                                Bahrain           BH\n",
       "18                             Bangladesh           BD\n",
       "19                               Barbados           BB\n",
       "20                                Belarus           BY\n",
       "21                                Belgium           BE\n",
       "22                                 Belize           BZ\n",
       "23                                  Benin           BJ\n",
       "24                                Bermuda           BM\n",
       "25                                 Bhutan           BT\n",
       "26        Bolivia, Plurinational State of           BO\n",
       "27                 Bosnia and Herzegovina           BA\n",
       "28                               Botswana           BW\n",
       "29                          Bouvet Island           BV\n",
       "..                                    ...          ...\n",
       "216          Tanzania, United Republic of           TZ\n",
       "217                              Thailand           TH\n",
       "218                           Timor-Leste           TL\n",
       "219                                  Togo           TG\n",
       "220                               Tokelau           TK\n",
       "221                                 Tonga           TO\n",
       "222                   Trinidad and Tobago           TT\n",
       "223                               Tunisia           TN\n",
       "224                                Turkey           TR\n",
       "225                          Turkmenistan           TM\n",
       "226              Turks and Caicos Islands           TC\n",
       "227                                Tuvalu           TV\n",
       "228                                Uganda           UG\n",
       "229                               Ukraine           UA\n",
       "230                  United Arab Emirates           AE\n",
       "231                        United Kingdom           GB\n",
       "232                         United States           US\n",
       "233  United States Minor Outlying Islands           UM\n",
       "234                               Uruguay           UY\n",
       "235                            Uzbekistan           UZ\n",
       "236                               Vanuatu           VU\n",
       "237     Venezuela, Bolivarian Republic of           VE\n",
       "238                              Viet Nam           VN\n",
       "239               Virgin Islands, British           VG\n",
       "240                  Virgin Islands, U.S.           VI\n",
       "241                     Wallis and Futuna           WF\n",
       "242                        Western Sahara           EH\n",
       "243                                 Yemen           YE\n",
       "244                                Zambia           ZM\n",
       "245                              Zimbabwe           ZW\n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the countries_en to country codes\n",
    "country_df = pd.read_csv(data_folder + countryfile, \n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         usecols=['English short name lower case', 'Alpha-2 code'],\n",
    "                         quotechar='\"')\n",
    "# rename columns\n",
    "country_df.rename(columns={\n",
    "    'Alpha-2 code':'country_code',\n",
    "    'English short name lower case': 'country_name'\n",
    "    }, inplace=True)\n",
    "\n",
    "# country_df['country_name'] = country_df.apply(\n",
    "#     lambda x: x['country_name'].split(',')[0] if ',' in x['country_name'] else x['country_name'],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]\n",
    "\n",
    "df_3 = df_2.copy()\n",
    "df_3 = explode(df_3,'countries_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_tags</th>\n",
       "      <th>labels_en</th>\n",
       "      <th>countries_en</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>allergens</th>\n",
       "      <th>allergens_en</th>\n",
       "      <th>traces</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_name quantity labels labels_tags labels_en   countries_en  \\\n",
       "173  Lion Peanut x2      NaN    NaN         NaN       NaN         France   \n",
       "174  Lion Peanut x2      NaN    NaN         NaN       NaN  United States   \n",
       "\n",
       "    ingredients_text allergens allergens_en traces         ...           \\\n",
       "173              NaN       NaN          NaN    NaN         ...            \n",
       "174              NaN       NaN          NaN    NaN         ...            \n",
       "\n",
       "    proteins_100g salt_100g  sodium_100g alcohol_100g  calcium_100g  \\\n",
       "173           NaN       NaN          NaN          NaN           NaN   \n",
       "174           NaN       NaN          NaN          NaN           NaN   \n",
       "\n",
       "     iron_100g  carbon-footprint_100g  nutrition-score-fr_100g  \\\n",
       "173        NaN                    NaN                      NaN   \n",
       "174        NaN                    NaN                      NaN   \n",
       "\n",
       "     nutrition-score-uk_100g  glycemic-index_100g  \n",
       "173                      NaN                  NaN  \n",
       "174                      NaN                  NaN  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how the explode function created another row because there were two countries for Lion Peanut x2\n",
    "df_3[df_3['product_name'].notna() & df_3['product_name'].str.contains('Lion Peanut x2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "# rename countries_en to country_name\n",
    "df_4.rename(columns={'countries_en':'country_name'}, inplace=True)\n",
    "\n",
    "df_4 = df_4.merge(country_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unassigned items is: 4421\n",
      "The important values are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Russia                       2203\n",
       "En                            477\n",
       "fr:deutschland                229\n",
       "Taiwan                        227\n",
       "Vietnam                       107\n",
       "de:allemagne                   92\n",
       "ch:suisse                      82\n",
       "European Union                 80\n",
       "South Korea                    67\n",
       "fr:schweiz                     49\n",
       "Republic of Macedonia          41\n",
       "fr:frankreich                  35\n",
       "Product name completed         34\n",
       "Brands completed               34\n",
       "Categories completed           34\n",
       "Nutrition facts completed      33\n",
       "Characteristics completed      33\n",
       "Quantity completed             33\n",
       "Photos uploaded                33\n",
       "Packaging completed            33\n",
       "Name: country_name, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_assigned = df_4[df_4['country_name'].notna() & df_4['country_code'].isna()][['country_name']]\n",
    "\n",
    "print(\"Number of unassigned items is: {}\".format(len(not_assigned)))\n",
    "print(\"The important values are: \")\n",
    "not_assigned.country_name.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to fix the country codes with the highest frequency, since the importance/effect of fixing the lower values will decrease as we descend through the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
